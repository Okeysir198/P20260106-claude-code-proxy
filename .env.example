# =============================================================================
# Claude Code Proxy Configuration
# =============================================================================
# Uncomment ONE provider section below to use it

# =============================================================================
# OPTION 1: NVIDIA NIM API (Recommended)
# =============================================================================
# Get your API key at https://build.nvidia.com/
# Browse models at https://build.nvidia.com/models
PREFERRED_PROVIDER="openai"
OPENAI_BASE_URL="https://integrate.api.nvidia.com/v1"
OPENAI_API_KEY="nvapi-..."
BIG_MODEL="nvidia/nemotron-3-nano-30b-a3b"
SMALL_MODEL="nvidia/nemotron-3-nano-30b-a3b"
# gpt-oss-120b has streaming issues - use nemotron instead
# BIG_MODEL="openai/gpt-oss-120b"
# SMALL_MODEL="openai/gpt-oss-120b"


# # =============================================================================
# # OPTION 2: Ollama Native (2nd Recommended)
# # =============================================================================
# # Uses native Ollama provider with proper context length support
# PREFERRED_PROVIDER="ollama"
# # Without Docker: use localhost
# OLLAMA_API_BASE="http://localhost:11434"
# # With Docker: use host.docker.internal
# # OLLAMA_API_BASE="http://host.docker.internal:11434"
# OLLAMA_NUM_CTX=128000
# BIG_MODEL="gpt-oss:20b"
# SMALL_MODEL="gpt-oss:20b"

# =============================================================================
# OPTION 3: Ollama via OpenAI-compatible API
# =============================================================================
# Alternative: Use Ollama through its OpenAI-compatible endpoint
# Note: This may not support num_ctx parameter
# PREFERRED_PROVIDER="openai"
# OPENAI_API_KEY="ollama-dummy-key"
# OPENAI_BASE_URL="http://localhost:11434/v1"
# BIG_MODEL="qwen2.5-coder:32b"
# SMALL_MODEL="qwen2.5-coder:14b"

# =============================================================================
# OPTION 4: OpenAI
# =============================================================================
# PREFERRED_PROVIDER="openai"
# OPENAI_API_KEY="your-openai-api-key"
# OPENAI_BASE_URL="https://api.openai.com/v1"
# BIG_MODEL="gpt-4.1"
# SMALL_MODEL="gpt-4.1-mini"

# =============================================================================
# OPTION 5: Google Gemini
# =============================================================================
# PREFERRED_PROVIDER="google"
# GEMINI_API_KEY="your-google-ai-studio-key"
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# =============================================================================
# OPTION 6: Google Vertex AI (ADC auth)
# =============================================================================
# PREFERRED_PROVIDER="google"
# USE_VERTEX_AUTH=true
# VERTEX_PROJECT="your-gcp-project"
# VERTEX_LOCATION="us-central1"
# BIG_MODEL="gemini-2.5-pro"
# SMALL_MODEL="gemini-2.5-flash"

# =============================================================================
# OPTION 7: Anthropic (passthrough proxy)
# =============================================================================
# PREFERRED_PROVIDER="anthropic"
# ANTHROPIC_API_KEY="your-anthropic-api-key"
# (BIG_MODEL and SMALL_MODEL are ignored - models pass through as-is)

# =============================================================================
# OPTION 8: OpenRouter (400+ models via unified API)
# =============================================================================
# Get your API key at https://openrouter.ai/keys
# Browse models at https://openrouter.ai/models
# PREFERRED_PROVIDER="openai"
# OPENAI_API_KEY="sk-or-v1-..."
# OPENAI_BASE_URL="https://openrouter.ai/api/v1"

# Top coding models:
# BIG_MODEL="qwen/qwen3-coder-480b-a35b-instruct"    # Best for agentic coding
# SMALL_MODEL="qwen/qwen3-coder-480b-a35b-instruct"
#
# Alternative coding models:
# BIG_MODEL="mistralai/devstral-2"                   # 123B dense, 256K context
# BIG_MODEL="x-ai/grok-3-beta"                       # xAI Grok 3
# BIG_MODEL="anthropic/claude-sonnet-4"              # Claude Sonnet 4
# BIG_MODEL="google/gemini-2.5-pro-preview"          # Gemini 2.5 Pro
# BIG_MODEL="openai/gpt-4.1"                         # GPT-4.1
#
# Free models (require "Free model training" enabled at https://openrouter.ai/settings/privacy):
# BIG_MODEL="google/gemini-2.0-flash-exp:free"
# SMALL_MODEL="google/gemini-2.0-flash-exp:free"

# # Paid models (no privacy settings needed):
# BIG_MODEL="google/gemini-2.5-flash"
# SMALL_MODEL="google/gemini-2.5-flash"
